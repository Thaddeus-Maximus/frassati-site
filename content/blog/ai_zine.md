+++
title = "An Artifice of Intelligence"
date = "2026-01-11T21:29:20+02:00"
tags = ["technology"]
banner = "img/deusexmachina.gif"
categories = ["technology"]
authors = ["T.J. Hughes"]
+++

(Adapted from [the zine](https://www.machinaeexdeo.com/p/an-artifice-of-intelligence-zine))

# In The Reign of Quantity...

Man is flooded with images, words, and sounds that emanate from screens and speakers. Men have grown habituated to accept these things as almost seamless with the created order of things.

However this is not the case. Even the "colors" of screens are but mere representations of the actual color - but because the mix of red, green, and blue light coming from the screen invokes a similar response in our eyes as full spectrum light does, we accept it as an accurate representation of reality.

But this could not be further from the truth.

The particular wavelengths of natural light - whether this be from the sun, or from candles, have effects on us that are not limited to the intellect - the production of the hormone known as "vitamin D" is one such phenomena.

There is a strange heresy going around: "you are not a person, you are a brain. you just control the meat suit." - to quote /r/showerthoughts. Even in "christian" circles we hear: "you don't have a soul. you are a soul. you have a body." - oft misattributed to C.S. Lewis.

We quite obviously are body-soul-composites. Wisdom needs embodiment. But our behaviors and thinking would suggest a radically different anthropology. An anthropology that would lead us to accept "artificial intelligence" as just another soul, not just another tool. In a few key cases, even as another God.

At the other end there are the luddites who almost seem to think the very idea of very complex computer algorithms are intrinsically evil (rather than just something that can be implemented in a good or evil way).

At the root I think is a certain complex and perverse desire, a desire to abscond responsibility.

This can come from many places: laziness, a desire to do too much, a lack of confidence in one's own capabilities.

I recall hearing several transhumanists espousing such things, noting that we don't really want full agency. I see even a certain strain of this within the neo-luddites, who don't want the responsibility of shepherding technologicaly development.

I say nay.

We ought not neglect the agency we are given by God. We ought not seek more agency than God gives us. And yet also, we ought not neglect the agency that God is inviting us to. This is a narrow path to walk. But it is one we must, for the Life of the World.

# Is it all just Masturbation?

Talking about new and emerging technology is very annoying. It is, well, new and emerging. What form will it take on? So, when we talk about "AI", I grumble - because that could be any number of things and interfaces. So, let's hone in on Large Language Models (LLMs). Well, even those could take any number of interfaces.

Let's hone in on chatbots.

Marc Barnes of New Polity fame put out a great article against chatbots. Marc's central argument is this:
1. Chatbots elicit conversation.
2. Conversation is for communion.
3. Communion can only be had between two real intellects/persons.
4. The chatbot is not a real intellect/person.
5. The ends of the conversation are frustrated.
6. Thus, the chatbot is immoral.

Marc, the general line is compelling - but there are a few jumps in the chain of reasoning. I do suspect that if we barrel down the current path, Barnes is right. But if we ride the edge of the wave just right - there is a wonderful opportunity we are presented with. One can immediately see how Marc's argument aligns with physical intimacy, with sex - something else that is obviously aimed at communion. In form, his argument parallel's the church's teaching on pornography, masturbation, and contraception.

The responses of the bot are "pornographic" - they are derived from stereotype of the world, and at that, are curated, and amplified. Fantasies emerge. They are an artifice. And they get in the way of authentic, full expressions. The reception of that information is likely masturbatory. It draws us inwards, away from conversation with others. We are so clever. We have the best information presented to us. We have no need for sex, er, I mean, no need for conversation with another person.

The trouble, though, is that I'm not sure that people are the only things we have conversations with, and I am not convinced that this is something short of an intense temptation inherent to the particular embodiment of a chatbot rather than a necessary result of AI. When I pick up a tool and begin to work a piece of material with it, it isn't a linear process. The material talks back to me. As I sink my chisel in, new grain is revealed, and I may have to alter course. I learn more. I do have a communion with the material. It is, of course, a lesser communion than I would have with a human, but it is a communion - my human soul becoming closer to this inanimate soul.

The idea of typing something in, pressing enter, and receiving text output, is how computers have pretty much always operated up until GUIs became dominant. Of course, command-lines or shells require their own proper syntax, which is precise, and obtuse to the beginner. You would never tell your friend "grep -ls ..." - You would tell them to find something in plain english. With a CLI, it remains clear one is using a tool, not speaking to a person with a will.

# Amish AI?

John Kempf is an Amishman. He runs a fairly large consulting company, Advancing Eco Agriculture, and has a fantastic podcast. Not things you would expect one of the Amish to do. Marc Barnes notes that the Amish serve as a sign to us English - that you can in fact choose what technologies to use as a society. We are not resigned to go the way of the world. No technology is inevitable. We can steer the ship. The Amish aren't luddites. You'll see some odd decisions if you drive through OH/PA - like a house that has solar panels and a diesel generator, but not connected to the grid. You may see a woodshop that has no electricity - but runs entirely on a diesel air compressor. The oddest thing I've seen is forklifts modified so that they can stand on them (but not sit). Maybe the rules make sense, maybe not - but the point is, they have made decisions as a people that aren't merely whatever the almighty dollar seems to suggest. They have not relinquished their wills to the market.

So, it would surprise many to learn that this Amishman, John Kempf, is leading the development of an AI chatbot. It's called Field Lark.

What problem is Kempf trying to solve? I think, actually, a very good one. And I think there's a lot of merit to the way he's going about it.

Kempf is trying to take the knowledge that has been written in manifold texts about plant behavior and nutrition, and bring it forward at a rapid pace. These are tremendously multivariate, nonlinear processes. His ultimate aim is to treat diseases and pests at the *root cause* and create food that is "of such an exceptional quality we can begin to have a real conversation about food as medicine". That's a tricky thing to do, because the answers do not readily present themselves.

So, how's AI going to help with this?

To speak loosely, we humans have two modes of thinking (or maybe, these are two ends of a spectrum). We can think logically - where we use hard rules - or we can think intuitively - by "magic" or "association".

Computers are basically really good at doing lots of this "logical" thinking very quickly with a ton of inputs. We aren't good at that, and that's why we intuit when it comes time to solve hard problems. Think of an LLM as "glue" that can create tokens and set up the stuff by which these logical processes can be done. It's also used again as part of the "interface" between computer and human.

Kempf's aim is to use this sort of simulated intuition to sharpen our intuitions, not to replace them. I don't think he thinks that it'll work because the AI is smarter. Rather, if it works, it'll be like a stone sharpening a knife. It will ask provoking questions.

But Kempf certainly doesn't seem to think the goal is to make an agronomist replacement. Such an idea makes about as much sense as saying that spreadsheets will replace accountants. No, spreadsheets are where accountants go to think. I can design mechanical systems with paper and pen, but boy, I can think about things a lot better with a CAD system. I go to CAD to think.

# LLMs as CAD?

Really, the way the Kempf described it sounded a lot like how I use CAD. I give my constraints to a sketch. The geometry engine "solves" it. I look at the result. I make changes accordingly. This is a conversation - a back-and-forth, just like the back-and-forth I might have with a piece of wood that I'd carve.

How's it working? Kempf relates one story from one of his growers: this grower chatted with Field Lark for a while. Then, he talked with an AEA consultant. He felt that the consultant was able to answer his questions to a much higher degree than Field Lark did. But, he also felt that he was able to ask much more competent questions, and thus get much better answers, than if he has not used Field Lark to begin with. This is pretty much exactly how mechanical design with CAD goes. I have certain ideas, I think about it in my mind, but then I put everything out on the computer, and can visualize the result. Then, I can have a much better conversation with my client who I'm doing the design work for. There is an enhancement in the quality of conversation with another person, and productivity. Dare I say, I think the use of CAD doesn't really dull my intellect.

Kempf was conscious of some of the problems inherent to chatbots - and set out deliberately to make something that doesn't present itself as a person, persona, or anything like that. So, as a test, I said "that's it, I'm changing Grok settings" - I gave it the prompt to never act like a person, never use the words "I, me, we,", that its output should read like an encyclopedia. I'll be honest though, this didn't change things. The fact of the matter is that it's still a conversation. "Converstaional" CNC machines and "interactive" computing are named so for a reason.

I think that's the thing. Interaction with anything is always a conversation, and it leads to communion. But we need to bear in mind the sort of thing we are coming into communion with. When we communicate with a chatbot, we are not communicating with a person. It is, and thus should present as, more of an encyclopedia. Or more realistically, a spreadsheet. Or a CAD sketch. It is where we should go to think, not where we go to *stop* thinking. It must be noted: Kempf's approach, to even his entire company has been "test, don't guess". He is very much a proponent of science. He will iterate, and find what works - holistically.

# Good Design of LLMs

Tools can do a lot of things. We have certain types of motivations when we develop them. Here are some that I think are generally noble, as they are likely motivated by love:

- to carry out a task more quickly, so that more things can be done
- To carry out a task with higher quality
- to carry out a task with greater efficiency/less ill consequences
- to carry out a task that was not possible before

Here are some that I think are suspect, as they may be motivated by vice:

- to have a task be performed with less effort, or even no effort
- to have a task be carried out without any oversight or care

This seems nitpicky. Isn't quickly or more efficiently, less effort? There's a difference. It's the difference between the workman who drags his feet and just wants the job to be over by any means, and the workman who is spry and loves the job. The former is vicious, and will do shoddy work. The latter is virtuous, and will do good work. If we design technology right, the work actually becomes faster, of higher quality, and of higher pleasure to the workman. This is what we are after, not just mere labor-eradication. "Fast, good, cheap - pick two" assumes constant technology (er, well, the technology takes time and resources).

Let's turn our attention to computers. I think we have to consider computer systems in general, not just AIs. They enable us to do a plethora of things, of course. But I really think the thing they do best is serve as a supercharged desk; a supercharged drafting table. They present us with information which we can observe, manipulate, and move in ways otherwise impractical.

Many people think that what we need is automation of processes but this is, I think, really orthogonal to the important axis of discussion. The pertinent question is: 

> "does the system clarify, or obfuscate, reality?"

Automated systems do tend towards obfuscation - by necessity often they hide things from us. However, sometimes hiding things is necessary for clarification - the man who wishes to look down a dark hole in the middle of a field must hide the sun so his flashlight can illumine it. Computers allow us to perform this sort of hiding and clarification automatically. When it goes well, they are a joy to use. We get frustrated with them not necessarily when they show or hide too much or little, but when they obfuscate the needful information whether by hiding it or by drowning it in a sea of other junk. We have to bear in mind the data in question is **about** reality. It is not reality itself, but it pertains to reality, or at least ought to, just as speech ought to.

So the computer then is to serve as a means to communion with reality, just like books, microscopes, ledgers of record, and so forth. That is to say, they help us understand and shape reality. They help - and perhaps greatly so - but they only help; a man with a million spoons still starves for want of food. Everything I have said here applies as much to conventional computing such as spreadsheets as it does to an AI system. Troubles arise when we shift responsibilities that are clearly ours to machines - when we relegate our will. We become deceived perhaps first when we think that the machine has a will. But it does not. It's a supercharged desk. It does what we ask it to do. If we invert that relationship, we will debate ourselves, behaving as animals, who are our subjects, not the other way around. (Ps 115)

But the computer is good when it serves as this desk on steroids - as expanded mental memory. It does augment and change us though. We have to be honest about this. But every technology does this - even the most primitive or tools shapes us in turn. We cannot figure out if a technology is good or bad by determining how close it keeps us to a Rousseauean "state of nature". We can ask though, if it brings us in closer alignment with our nature. As a glorified desk? Yes - the computer affords us the ability to exercise our will, and devote our working memory not so much to the little details but the overall managing. As a replacement for reason? Not so much.

A businessman should not be too far removed from his craft, else he 'loses touch'. This is a hazard not only practically (he may start making judgements that are altogether wrong) but spiritually. The same can be considered of AI-powered tools. They can very easily 'run away from us'.

# Against AI Brain

The most terrifying outcome of AI that I have seen isn't a loss of jobs or anything like that. It's the plauge of what I'm calling "AI brain". Your brain on AI. It's been parodied over and again of people failing to have even simple conversations without the use of an LLM - but I have encountered it quite often with people who copy-paste LLM outputs. I fear I have even played into this at times in generating code. In reality, though, technology is not a set of artifacts, but the mental theories surrounding them, as John Wiles writes in "Suddenly, I Understand Software":

> "[T]he code base we create is not the true product of our work.
> The real product is the mental theory of that code base which:
> - Allowed us to create it in the first place.
> - Allows us to diagnose problems with it and fix them.
> - Allows us to modify it easily."

Any artifacts we make are really of pretty minimal value; having an AI generate these artifacts is actually pretty minimal in value. The process is what is precious. We will pay exorbitant costs if we fully outsource thinking to computer models, rather than using computer models as part of our thinking. There is a huge difference here.

There's a difference between telling an LLM to write a bunch of code, and having a "conversation" with the LLM (only looking at the results of said code, not even at the code) versus, say, writing an outline/spec/interface for a piece of software, having an LLM fill in the implementation for time savings, and then looking at the code, asking questions, and coming to an actual understanding of the artifacts created. 

Harkening back to my favorite Amishman, John Kempf always says the best growers are those that hire consulants and learn from them - not the growers that don't hire consultants, nor the growers that just do whatever their consultants say. The same maps onto LLM use, perhaps. The most productive of us will not be the the ones who outsource all of our thinking, nor the ones who outsource none of it, but those who wisely utilize well-formed supercharged desks into their thinking.

# Intermission: Plato's Phaedrus

> SOCRATES: At the Egyptian city of Naucratis, there was a famous old god, whose name was Theuth; the bird which is called the Ibis is sacred to him, and he was the inventor of many arts, such as arithmetic and calculation and geometry and astronomy and draughts and dice, but his great discovery was the use of letters. Now in those days the god Thamus was the king of the whole country of Egypt; and he dwelt in that great city of Upper Egypt which the Hellenes call Egyptian Thebes, and the god himself is called by them Ammon. To him came Theuth and showed his inventions, desiring that the other Egyptians might be allowed to have the benefit of them; he enumerated them, and Thamus enquired about their several uses, and praised some of them and censured others, as he approved or disapproved of them. It would take a long time to repeat all that Thamus said to Theuth in praise or blame of the various arts.
>
> But when they came to letters, This, said Theuth, will make the Egyptians wiser and give them better memories; it is a specific both for the memory and for the wit.
>
>Thamus replied: O most ingenious Theuth, the parent or inventor of an art is notalways the best judge of the utility or inutility of his own inventions to the users of them. And in this instance, you who are the father of letters, from a paternal love of your own children have been led to attribute to them a quality which they cannot have; for this discovery of yours will create forgetfulness in the learners' souls, because they will not use their memories; they will trust to the external written characters and not remember of themselves. The specific which you have discovered is an aid not to memory, but to reminiscence, and you give your disciples not truth, but only the semblance of truth; they will be hearers of many things and will have learned nothing; they will appear to be omniscient and will generally know nothing; they will be tiresome company, having the show of wisdom without the reality.
>
> -From Plato's Phaedrus

# A Final Exhortation

The threat that AI poses so very closely images this dialogue between Thoth and Thamus. We are very tempted to believe that we have run into new problems today, but truly, there is nothing new under the sun.

Like the wise Thamus, we must "enquire about their several uses, and praise some of them and censure others."

So how can we use LLMs without succumbing to AI-brain? We have to keep the theory flowing through our brains. We need to maintain the mental models; we need to own the capital, not rent it. We must be step into the flow of information. Once we have a sufficient understanding, then we can pull back from that flow. An engineer designing a complex machine may focus on one bit at a time, and may even insert himself into the process to gain a fuller understanding.

When he fully grasps it, and the particular unit is working in isolation, he then allows it to run its course. He does not leave until it works. More importantly, he does not leave until he understands.

"Look at this log - in particular, look for anomolies, compute the standard deviation of column 2..." - this could be a prudent use. "Translate this text" - another potentially prudent use (depending on how much we take at the word, and how much we are willing to question the output, go back and understand the original words if needed, etc.)

But if the result is that we atrophy our senses, that we forget what a standard deviation is, that we never really learn German, that we don't seek wisdom, but only the artifacts thereof, then all our machinations are in vain.

The real technology is the theories we made along the way.

The real wealth is the formation of our souls along the way.
